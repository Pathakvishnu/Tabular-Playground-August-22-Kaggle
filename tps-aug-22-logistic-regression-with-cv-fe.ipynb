{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nfrom sklearn.metrics import r2_score,roc_auc_score\n\n!pip install feature_engine\nimport feature_engine as fe\nfrom colorama import Fore, Back, Style\n\nimport xgboost\nimport random\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.linear_model import LogisticRegression,HuberRegressor\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom feature_engine.encoding import WoEEncoder\nfrom sklearn.metrics import roc_auc_score\n\nsns.set()\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:49:43.460885Z","iopub.execute_input":"2022-08-28T10:49:43.461323Z","iopub.status.idle":"2022-08-28T10:49:59.379387Z","shell.execute_reply.started":"2022-08-28T10:49:43.461237Z","shell.execute_reply":"2022-08-28T10:49:59.378199Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#### Read the data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-aug-2022/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-aug-2022/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:15:55.568544Z","iopub.execute_input":"2022-08-28T11:15:55.568968Z","iopub.status.idle":"2022-08-28T11:15:55.737050Z","shell.execute_reply.started":"2022-08-28T11:15:55.568934Z","shell.execute_reply":"2022-08-28T11:15:55.735833Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"#### Understanding the data","metadata":{}},{"cell_type":"code","source":"display(train.head())\n\nprint(f'Train data shape is = {train.shape}')\nprint(f'Test data shape is = {test.shape}')\n\nprint(\"\\n\"*1)\n\nprint(f'Train data missing value is = {format(100* train.isna().sum().sum()/(len(train)*25))}')\nprint(f'Test data missing value is  = {format(100* test.isna().sum().sum()/(len(test)*25))}')","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:50:14.942978Z","iopub.execute_input":"2022-08-28T10:50:14.943409Z","iopub.status.idle":"2022-08-28T10:50:15.003048Z","shell.execute_reply.started":"2022-08-28T10:50:14.943375Z","shell.execute_reply":"2022-08-28T10:50:15.001927Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.heatmap(train.isnull())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:50:17.713581Z","iopub.execute_input":"2022-08-28T10:50:17.714015Z","iopub.status.idle":"2022-08-28T10:50:19.237088Z","shell.execute_reply.started":"2022-08-28T10:50:17.713979Z","shell.execute_reply":"2022-08-28T10:50:19.235805Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"1. Most of the measurement features have null values","metadata":{}},{"cell_type":"markdown","source":"### Feature Distribution","metadata":{}},{"cell_type":"code","source":"plt.style.use(\"fivethirtyeight\")\nuseful_cols=[col for col in train.columns if col not in [\"id\",\"failure\"]]\ncols_dist = [col for col in useful_cols if train[col].dtypes not in ['object']]\ncolor_ = [ '#9D2417', '#AF41B4', '#003389' ,'#3C5F41',  '#967032', '#2734DE'] \ncmap_ = ['mako', 'rainbow', 'crest']\n\nplt.figure(figsize= (20,22))\nfor i,col in enumerate(train[useful_cols].columns):\n    rand_col = color_[random.sample(range(6), 1)[0]]\n    plt.subplot(8,3, i+1)\n    if col in cols_dist:\n        \n        sns.histplot(data=train,x=train[col],hue=train['failure'], color = rand_col, fill = rand_col)\n        plt.title(col, color = 'black')\n        plt.ylabel(\" \")\n        plt.xlabel(\" \")\n        plt.tight_layout()\n    else:\n        sns.countplot(data = train , x = col, hue=train['failure'], palette = cmap_[random.sample(range(3), 1)[0]] )\n        plt.title(col, color = 'black')\n        plt.ylabel(\" \")\n        plt.xlabel(\" \")\n        plt.legend(loc='upper right', borderaxespad=0)\n        plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:50:32.719022Z","iopub.status.idle":"2022-08-28T10:50:32.719591Z","shell.execute_reply.started":"2022-08-28T10:50:32.719322Z","shell.execute_reply":"2022-08-28T10:50:32.719349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class distribution \n# 0 - not failed 1 - failed\ntrain['failure'].value_counts(normalize=True).plot(kind='bar')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:52:20.637732Z","iopub.execute_input":"2022-08-28T10:52:20.638187Z","iopub.status.idle":"2022-08-28T10:52:20.855825Z","shell.execute_reply.started":"2022-08-28T10:52:20.638154Z","shell.execute_reply":"2022-08-28T10:52:20.854509Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train['product_code'],train['failure'],normalize=True).plot(kind='bar')\nplt.show()\n# so we have approximately equal distribution of classes accross different product type","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:52:23.291951Z","iopub.execute_input":"2022-08-28T10:52:23.292384Z","iopub.status.idle":"2022-08-28T10:52:23.571568Z","shell.execute_reply.started":"2022-08-28T10:52:23.292349Z","shell.execute_reply":"2022-08-28T10:52:23.570395Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(22,6))\nplt.subplot(1,2,1)\nsns.countplot(train['product_code'])\nplt.title(\"Train Data Product Code\")\nplt.subplot(1,2,2)\nsns.countplot(test['product_code'])\nplt.title(\"Test Data Product Code\")\nplt.show()\n\n# product code is different in train and test data","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:52:25.740410Z","iopub.execute_input":"2022-08-28T10:52:25.740845Z","iopub.status.idle":"2022-08-28T10:52:26.142065Z","shell.execute_reply.started":"2022-08-28T10:52:25.740808Z","shell.execute_reply":"2022-08-28T10:52:26.140795Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Note: \nAs per this [discussion](https://www.kaggle.com/competitions/tabular-playground-series-aug-2022/discussion/342403) \nThe public LB only compose of product code F data and rest product code G,H,I data in private LB.\nTo support this see below data. This is just an **assumption** we are making and so just believe in **cross validation technique**.\n","metadata":{}},{"cell_type":"code","source":"display(pd.DataFrame(test['product_code'].value_counts(normalize=True)))","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:52:29.412841Z","iopub.execute_input":"2022-08-28T10:52:29.413285Z","iopub.status.idle":"2022-08-28T10:52:29.426814Z","shell.execute_reply.started":"2022-08-28T10:52:29.413247Z","shell.execute_reply":"2022-08-28T10:52:29.425591Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"cat_feat = list()\nnum_feat = list()\nfor col in train.columns:\n    if col in ['failure','id']:\n        continue\n    if train[col].dtype==\"O\":\n        cat_feat.append(col)\n    else:\n        num_feat.append(col)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:52:31.927964Z","iopub.execute_input":"2022-08-28T10:52:31.928371Z","iopub.status.idle":"2022-08-28T10:52:31.935930Z","shell.execute_reply.started":"2022-08-28T10:52:31.928339Z","shell.execute_reply":"2022-08-28T10:52:31.934322Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# corr = train[train['product_code']=='A'].corr()['measurement_0'].sort_values(ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading Feature \n\nThe loading feature seems to have right skewed distribution.\n\nLet's apply log transformation to make the distribution more normal.","metadata":{}},{"cell_type":"code","source":"## training data\n\nplt.figure(figsize= (22,5))\nplt.subplot(1,2,1)\nsns.histplot(train['loading'],kde=True,color='coral')\nplt.title(\"Orignal\")\nplt.subplot(1,2,2)\nsns.histplot(np.log(train[\"loading\"]),kde=True)\nplt.title(\"Log transformed\")\nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:52:35.311413Z","iopub.execute_input":"2022-08-28T10:52:35.312462Z","iopub.status.idle":"2022-08-28T10:52:36.607054Z","shell.execute_reply.started":"2022-08-28T10:52:35.312420Z","shell.execute_reply":"2022-08-28T10:52:36.605672Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"## testing data\n\nplt.figure(figsize= (22,5))\nplt.subplot(1,2,1)\nsns.histplot(test['loading'],kde=True,color='coral')\nplt.title(\"Orignal\")\nplt.subplot(1,2,2)\nsns.histplot(np.log(test[\"loading\"]),kde=True)\nplt.title(\"Log transformed\")\nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T10:52:36.914650Z","iopub.execute_input":"2022-08-28T10:52:36.915090Z","iopub.status.idle":"2022-08-28T10:52:38.103677Z","shell.execute_reply.started":"2022-08-28T10:52:36.915055Z","shell.execute_reply":"2022-08-28T10:52:38.102500Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"target = train.pop('failure')\ntarget_mean = np.mean(target)\nprint(f\"target mean --> {target_mean}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:16:04.831009Z","iopub.execute_input":"2022-08-28T11:16:04.832494Z","iopub.status.idle":"2022-08-28T11:16:04.842559Z","shell.execute_reply.started":"2022-08-28T11:16:04.832443Z","shell.execute_reply":"2022-08-28T11:16:04.840810Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([train, test])\ntrain.shape,test.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:50:52.081936Z","iopub.execute_input":"2022-08-28T11:50:52.082719Z","iopub.status.idle":"2022-08-28T11:50:52.098642Z","shell.execute_reply.started":"2022-08-28T11:50:52.082667Z","shell.execute_reply":"2022-08-28T11:50:52.097611Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\ndata['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\ndata['area'] = data['attribute_2'] * data['attribute_3']\n\ndata['loading'] = np.log(data['loading'])\ndata['count_null'] = data.isnull().sum(axis=1)\n\n# nan_feat = list()\n# for col in train.columns:\n#     if train[col].isnull().sum()>0:\n#         nan_feat.append(col)\n#         data[\"nan_\"+col] = data[col].isnull().map(lambda k: 1 if k else 0)\n\n\nfeature = [f for f in test.columns if f.startswith('measurement') or f=='loading']","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:50:53.396618Z","iopub.execute_input":"2022-08-28T11:50:53.397329Z","iopub.status.idle":"2022-08-28T11:50:53.420553Z","shell.execute_reply.started":"2022-08-28T11:50:53.397293Z","shell.execute_reply":"2022-08-28T11:50:53.419253Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing : Filling Missing Values + Encoding Categorical Variable using WeightofEvidence Technique","metadata":{}},{"cell_type":"code","source":"# plt.figure(figsize=(22,12))\n# sns.heatmap(data[data.product_code=='I'].corr(),annot=True,fmt=\".2f\")","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:26:25.996580Z","iopub.execute_input":"2022-08-28T11:26:25.997076Z","iopub.status.idle":"2022-08-28T11:26:26.003202Z","shell.execute_reply.started":"2022-08-28T11:26:25.997040Z","shell.execute_reply":"2022-08-28T11:26:26.001502Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"full_fill_dict ={}\nfull_fill_dict['measurement_17'] = {\n    'A': ['measurement_5','measurement_6','measurement_8','measurement_7'],\n    'B': ['measurement_4','measurement_5','measurement_7','measurement_9'],\n    'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n    'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n    'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n    'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n    'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n    'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n    'I': ['measurement_3','measurement_7','measurement_8','measurement_9']\n}\n\n\n# collect the name of the next 10 best measurement columns sorted by correlation (except 17 already done above):\ncol = [col for col in test.columns if 'measurement' not in col]+ ['loading','m3_missing','m5_missing']\na = []\nb =[]\n\nfor x in range(3,17):\n    corr = np.absolute(data.drop(col, axis=1).corr()[f'measurement_{x}']).sort_values(ascending=False)\n    a.append(np.round(np.sum(corr[1:4]),3)) # we add the 3 first lines of the correlation values to get the \"most correlated\"\n    b.append(f'measurement_{x}')\nc = pd.DataFrame()\nc['Selected columns'] = b\nc['correlation total'] = a","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:50:57.559632Z","iopub.execute_input":"2022-08-28T11:50:57.560697Z","iopub.status.idle":"2022-08-28T11:50:58.444288Z","shell.execute_reply.started":"2022-08-28T11:50:57.560652Z","shell.execute_reply":"2022-08-28T11:50:58.443099Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"c = c.sort_values(by = 'correlation total',ascending=False).reset_index(drop = True)\nprint(f'Columns selected by correlation sum of the 3 first rows : ')\ndisplay(c.head(10))","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:50:59.151573Z","iopub.execute_input":"2022-08-28T11:50:59.152494Z","iopub.status.idle":"2022-08-28T11:50:59.167450Z","shell.execute_reply.started":"2022-08-28T11:50:59.152452Z","shell.execute_reply":"2022-08-28T11:50:59.166146Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# calculating top 4 correlated features for each measurement column w.r.t each product code\n\nfor i in range(10):\n    measurement_col = 'measurement_' + c.iloc[i,0][12:] # we select the next best correlated column \n    fill_dict = {}\n    for x in data.product_code.unique() : \n        corr = np.absolute(data[data.product_code == x].drop(col, axis=1)\n                           .corr()[measurement_col]).sort_values(ascending=False)\n\n        measurement_col_dic = {}\n        measurement_col_dic[measurement_col] = corr[1:5].index.tolist()\n        fill_dict[x] = measurement_col_dic[measurement_col]\n\n    full_fill_dict[measurement_col] =fill_dict","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:51:10.773410Z","iopub.execute_input":"2022-08-28T11:51:10.774841Z","iopub.status.idle":"2022-08-28T11:51:12.003339Z","shell.execute_reply.started":"2022-08-28T11:51:10.774785Z","shell.execute_reply":"2022-08-28T11:51:12.002140Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"feature = [f for f in data.columns if f.startswith('measurement') or f=='loading']\nnullValue_cols = [col for col in train.columns if train[col].isnull().sum()!=0]","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:51:16.381624Z","iopub.execute_input":"2022-08-28T11:51:16.382146Z","iopub.status.idle":"2022-08-28T11:51:16.400402Z","shell.execute_reply.started":"2022-08-28T11:51:16.382106Z","shell.execute_reply":"2022-08-28T11:51:16.399384Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"## Filling NA values using HuberRegressor & KNNImputer\n## HuberRegressor is used when except for target feature all other correlated feature column has no null values i.e\n## for e.g. for measurement_17 product_code A correlated feature is ['measurement_5','measurement_6','measurement_8']\n## Then HuberRegressor will be used on those samples where ['measurement_5','measurement_6','measurement_8'] columns has \n## no null values \n## If above condition doesn't satisfy then we apply KNNImputer\n\nfor code in data.product_code.unique():\n    total_na_filled_by_linear_model = 0\n    print(f'\\n-------- Product code {code} ----------\\n')\n    print(f'filled by linear model :')\n    for measurement_col in list(full_fill_dict.keys()):\n        tmp = data[data.product_code == code]\n        column = full_fill_dict[measurement_col][code]\n        tmp_train = tmp[column+[measurement_col]].dropna(how='any')\n        tmp_test = tmp[(tmp[column].isnull().sum(axis=1)==0)&(tmp[measurement_col].isnull())]\n\n        model = HuberRegressor(epsilon=1.9)\n        model.fit(tmp_train[column], tmp_train[measurement_col])\n        data.loc[(data.product_code==code)&(data[column].isnull().sum(axis=1)==0)\n                 &(data[measurement_col].isnull()),measurement_col] = model.predict(tmp_test[column])\n        print(f'{measurement_col} : {len(tmp_test)}')\n        total_na_filled_by_linear_model += len(tmp_test)\n        \n    # others NA columns:\n    NA = data.loc[data[\"product_code\"] == code,nullValue_cols ].isnull().sum().sum()\n    model1 = KNNImputer(n_neighbors=3)\n    data.loc[data.product_code==code, feature] = model1.fit_transform(data.loc[data.product_code==code, feature])\n    print(f'\\n{total_na_filled_by_linear_model} filled by linear model ') \n    print(f'{NA} filled by KNN ')","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:49:21.296679Z","iopub.execute_input":"2022-08-28T11:49:21.297133Z","iopub.status.idle":"2022-08-28T11:49:43.471831Z","shell.execute_reply.started":"2022-08-28T11:49:21.297098Z","shell.execute_reply":"2022-08-28T11:49:43.470399Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"data['measurement_avg'] = data[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\ndf_train = data.iloc[:train.shape[0],:]\ndf_test = data.iloc[train.shape[0]:,:]\n\nwoe_encoder = WoEEncoder(variables=['attribute_0'])\nwoe_encoder.fit(df_train, target)\ndf_train = woe_encoder.transform(df_train)\ndf_test = woe_encoder.transform(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:49:47.633582Z","iopub.execute_input":"2022-08-28T11:49:47.634167Z","iopub.status.idle":"2022-08-28T11:49:47.725608Z","shell.execute_reply.started":"2022-08-28T11:49:47.634124Z","shell.execute_reply":"2022-08-28T11:49:47.723975Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"df_train['measurement(3*5)'] = df_train['measurement_3'] * df_train['measurement_5']\ndf_test['measurement(3*5)'] = df_test['measurement_3'] * df_test['measurement_5']\n\ndf_train['missing(3*5)'] = df_train['m5_missing'] * (df_train['m3_missing'])\ndf_test['missing(3*5)'] = df_test['m5_missing'] * (df_test['m3_missing'])","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:49:54.625391Z","iopub.execute_input":"2022-08-28T11:49:54.626249Z","iopub.status.idle":"2022-08-28T11:49:54.635934Z","shell.execute_reply.started":"2022-08-28T11:49:54.626205Z","shell.execute_reply":"2022-08-28T11:49:54.634696Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"features = ['loading', 'attribute_0', 'measurement_17', 'measurement_0', 'measurement_1','measurement_2','count_null','area', 'm3_missing', 'm5_missing', \n        'measurement_avg','measurement(3*5)','missing(3*5)']\n\n\"\"\"\n'nan_loading', 'nan_measurement_3', \n        'nan_measurement_4','nan_measurement_5', 'nan_measurement_6', 'nan_measurement_7',\n       'nan_measurement_8', 'nan_measurement_9', 'nan_measurement_10',\n       'nan_measurement_11', 'nan_measurement_12', 'nan_measurement_13',\n       'nan_measurement_14', 'nan_measurement_15', 'nan_measurement_16',\n       'nan_measurement_17',\n\n\"\"\"\ndf_train['failure'] = target","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:49:59.155993Z","iopub.execute_input":"2022-08-28T11:49:59.157203Z","iopub.status.idle":"2022-08-28T11:49:59.163642Z","shell.execute_reply.started":"2022-08-28T11:49:59.157156Z","shell.execute_reply":"2022-08-28T11:49:59.162795Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"### Standard Scaler","metadata":{}},{"cell_type":"code","source":"def scale(train_data, val_data, test_data, feats):\n    scaler = StandardScaler()\n    scaled_train = scaler.fit_transform(train_data[feats])\n    scaled_val = scaler.transform(val_data[feats])\n    scaled_test = scaler.transform(test_data[feats])\n    new_train = train_data.copy()\n    new_val = val_data.copy()\n    new_test = test_data.copy()\n    new_train[feats] = scaled_train\n    new_val[feats] = scaled_val\n    new_test[feats] = scaled_test\n    return new_train, new_val, new_test","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:25:09.473092Z","iopub.execute_input":"2022-08-28T11:25:09.473888Z","iopub.status.idle":"2022-08-28T11:25:09.479720Z","shell.execute_reply.started":"2022-08-28T11:25:09.473852Z","shell.execute_reply":"2022-08-28T11:25:09.478882Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"N_FOLDS = 5\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=22)\ny_oof = np.zeros(df_train[features].shape[0])\ny_test = np.zeros(df_test[features].shape[0])\nlogistic_auc = 0\nix = 0\nfeature_importance = []\n\nfor train_ind, val_ind in skf.split(df_train[features], df_train[['failure']]):\n    print(f\"******* Fold {ix} ******* \")\n    tr_x, val_x = (\n        df_train[features].iloc[train_ind].reset_index(drop=True),\n        df_train[features].iloc[val_ind].reset_index(drop=True),\n    )\n    tr_y, val_y = (\n        df_train['failure'].iloc[train_ind].reset_index(drop=True),\n        df_train['failure'].iloc[val_ind].reset_index(drop=True),\n    )\n    \n    tr_x,val_x,test_x = scale(tr_x, val_x, df_test[features], features)\n    \n    clf = LogisticRegression(max_iter=500, C=0.0001, penalty='l2',solver='newton-cg')\n    \n    clf.fit(tr_x, tr_y)\n    feature_importance.append(clf.coef_.ravel())\n    preds = clf.predict_proba(val_x)[:,1]\n    \n    roc_score = roc_auc_score(val_y, preds)\n    \n    logistic_auc += roc_score/5\n\n    print('VAL_ROC-AUC:', round(roc_score, 5))\n    \n    y_oof[val_ind] = y_oof[val_ind] + preds\n\n    preds_test = clf.predict_proba(test_x)[:,1]\n    y_test = y_test + preds_test / N_FOLDS\n    ix = ix + 1\n    \nprint(f\"{Fore.GREEN}{Style.BRIGHT}Average auc = {round(logistic_auc, 5)}{Style.RESET_ALL}\")\nprint(f\"{Fore.BLUE}{Style.BRIGHT}OOF auc = {round(roc_auc_score(df_train[['failure']], y_oof), 5)}{Style.RESET_ALL}\")\n\nfeature_importance.append(clf.coef_.ravel())\nimportance_df = pd.DataFrame(np.array(feature_importance).T, index=df_train[features].columns)\nimportance_df['mean'] = importance_df.mean(axis=1).abs()\nimportance_df['feature'] = df_train[features].columns\nimportance_df = importance_df.sort_values('mean', ascending=True).reset_index()\n\nfig, ax = plt.subplots(figsize=(12, 8), facecolor='#EAECEE')\nplt.barh(importance_df.index, importance_df['mean'], color='lightseagreen')\n\nplt.yticks(ticks=importance_df.index, labels=importance_df['feature'])\nplt.title('LogisticRegression feature importances', fontsize=20, y= 1.05)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T11:50:02.345504Z","iopub.execute_input":"2022-08-28T11:50:02.346378Z","iopub.status.idle":"2022-08-28T11:50:03.619073Z","shell.execute_reply.started":"2022-08-28T11:50:02.346338Z","shell.execute_reply":"2022-08-28T11:50:03.617735Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"y_pred = df_train[['failure']].copy(deep=True)\ny_pred = y_pred.rename(columns={\"failure\": \"prediction\"})\ny_pred[\"prediction\"] = y_oof\n\nroc_auc_score(df_train[['failure']],y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:07:36.591819Z","iopub.execute_input":"2022-08-28T07:07:36.592498Z","iopub.status.idle":"2022-08-28T07:07:36.616189Z","shell.execute_reply.started":"2022-08-28T07:07:36.592462Z","shell.execute_reply":"2022-08-28T07:07:36.615044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## distribution of scores on test data -- logistic regression model\nplt.hist(y_test, bins=50)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:10:48.248264Z","iopub.execute_input":"2022-08-28T07:10:48.248717Z","iopub.status.idle":"2022-08-28T07:10:48.584567Z","shell.execute_reply.started":"2022-08-28T07:10:48.248682Z","shell.execute_reply":"2022-08-28T07:10:48.583405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_log = pd.read_csv('../input/tabular-playground-series-aug-2022/sample_submission.csv')\nsub_log['failure'] = preds_test\n\nsub_log.to_csv(\"submission.csv\", index=False)\n# Public Score: 0.59172\n","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:11:02.839444Z","iopub.execute_input":"2022-08-28T07:11:02.840066Z","iopub.status.idle":"2022-08-28T07:11:02.905596Z","shell.execute_reply.started":"2022-08-28T07:11:02.840029Z","shell.execute_reply":"2022-08-28T07:11:02.904738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}